{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3ef6a0e",
   "metadata": {},
   "source": [
    "### BERT Pre-train on GPU\n",
    "\n",
    "Succesfully run on Google Colab GPU as of 6/6/2020 at 9:45am    \\\n",
    "Saved as model_ft6.pth      \\\n",
    "2 Epochs, Batch Size 32       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c8c055",
   "metadata": {},
   "outputs": [],
   "source": [
    "import BERT_Project_Package as bpp\n",
    "\n",
    "#For all your pickle needs\n",
    "import pickle\n",
    "\n",
    "#General stuff\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#For Train and Test Split\n",
    "import random\n",
    "\n",
    "#For Running BERT\n",
    "from transformers import BertTokenizer, BertForPreTraining, BertModel, TFBertForMaskedLM, BertConfig, BertForMaskedLM\n",
    "import torch\n",
    "\n",
    "#Data preparation for Fine tuning\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "#For fine-tuning BERT\n",
    "import torch\n",
    "from transformers import BertModel\n",
    "\n",
    "#Initialize optimizer for pre-training\n",
    "from transformers import AdamW\n",
    "\n",
    "#For splitting tuples\n",
    "import ast\n",
    "\n",
    "#For progress bar\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368630b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "#initialize model\n",
    "model = BertForMaskedLM.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dad7b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Text Data\n",
    "import json\n",
    "with open('easier.json') as d:\n",
    "    x_dict = json.load(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cd61d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate, test = bpp.trainvaltest(x_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3a9360",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create necessary data input for both NSP and MLM task\n",
    "my_inputs = bpp.nsp_mlm(train)\n",
    "my_inputs_test = bpp.nsp_mlm(validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9852cf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = bpp.TorchDataset(my_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6edc4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size = 16, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff2a748",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the training parameters\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abee762e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the device, we'll want to use GPU for our training, will have to purchase\n",
    "#This is what that looks like: https://cloud.google.com/tpu/docs/quickstart\n",
    "model.to(device) #MLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38f2fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Activate our model's training mode\n",
    "model.train() #MLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9256f547",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set learn rate\n",
    "optim = AdamW(model.parameters(), lr = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8795eaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set this as needed, we'll want to do more\n",
    "epochs = 2\n",
    "\n",
    "#set training loop\n",
    "for epoch in range(epochs):\n",
    "    loop = tqdm(dataloader, leave = True)\n",
    "    for batch in loop: \n",
    "    #for every loop calculate the gradient\n",
    "        optim.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device) #this will put this to GPU if device = GPU\n",
    "        token_type_ids = batch['token_type_ids'].to(device) #for NSP and MLM, or NSP Only\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        #Now we have out ids, our token ids (for NSP and MLM, or NSP only), our masked data, and our true labels, we can process\n",
    "        #outputs = model(input_ids, token_type_ids = token_type_ids, attention_mask = attention_mask, labels = labels) for MLM only\n",
    "        outputs = model(input_ids, token_type_ids = token_type_ids, attention_mask = attention_mask, labels = labels)\n",
    "        loss = outputs.loss\n",
    "        #loss is difference between our prediction and our labels\n",
    "        #Calculate loss for every parameter in our model to calculate gradient using optimizer\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        #takes a step to optimize based on our calculated loss\n",
    "\n",
    "        #For each loop, show the epoch and the loss\n",
    "        loop.set_description(f'Epoch {epoch}')\n",
    "        loop.set_postfix(loss = loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9bd97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'model_ft6.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
